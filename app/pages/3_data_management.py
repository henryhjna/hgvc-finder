"""
ë°ì´í„° ê´€ë¦¬ í˜ì´ì§€
ìŠ¤í¬ë˜í•‘ ì‹¤í–‰, MF ë°ì´í„° ì—…ë¡œë“œ, DB ìƒíƒœ í™•ì¸
"""
import streamlit as st
import pandas as pd
from datetime import datetime
from pathlib import Path
import logging

import sys
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from utils.database import (
    get_session, get_all_listings, get_all_mf_references,
    upsert_listing, add_mf_reference, clear_mf_references,
    get_recent_scrape_logs, create_scrape_log, complete_scrape_log,
    Listing, MFReference
)
from utils.matching import normalize_resort_name
from scrapers.tug_scraper import TUGScraper
from scrapers.redweek_scraper import RedWeekScraper
from scrapers.smtsn_scraper import SMTSNScraper
from config import UI_TEXT


# ê° ìŠ¤í¬ë˜í•‘ ì†ŒìŠ¤ ì •ë³´
SCRAPER_INFO = {
    'tug': {
        'name': 'TUG Marketplace',
        'url': 'tug2.com/timesharemarketplace',
        'rating': 'â­â­ 2.4/5',
        'pros': [
            'ë¬´ë£Œ ë¦¬ìŠ¤íŒ… ê²€ìƒ‰',
            'HGVC ë§¤ë¬¼ ë§ìŒ',
            'í¬ëŸ¼ ì •ë³´ í’ë¶€',
        ],
        'cons': [
            'ë°ì´í„° ê²€ì¦ ì—†ìŒ - íŒë§¤ìê°€ ì•„ë¬´ê±°ë‚˜ ì…ë ¥ ê°€ëŠ¥',
            'ì‚¬ê¸° ë¦¬ìŠ¤íŒ… ì‹ ê³ í•´ë„ ë°©ì¹˜ë¨',
            'MF ì •ë³´ ë¶€ì •í™•í•œ ê²½ìš° ë§ìŒ',
        ],
        'warning': 'âš ï¸ íŒë§¤ì ì…ë ¥ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ í‘œì‹œí•˜ë¯€ë¡œ ì‹¤ì œ ë§¤ë¬¼ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ. ë°˜ë“œì‹œ ì§ì ‘ í™•ì¸ í•„ìš”!',
    },
    'redweek': {
        'name': 'RedWeek',
        'url': 'redweek.com',
        'rating': 'â­â­â­â­ 4.2/5',
        'pros': [
            'BBB A+ ë“±ê¸‰, 20ë…„ ìš´ì˜',
            '300ë§Œ+ ì‚¬ìš©ì',
            'Verified ë°°ì§€ë¡œ ê²€ì¦ëœ ë§¤ë¬¼ í‘œì‹œ',
            'ê³ ê° ì„œë¹„ìŠ¤ ì‘ë‹µ ë¹ ë¦„',
        ],
        'cons': [
            'ìœ ë£Œ ë©¤ë²„ì‹­ í•„ìš” ($18.99/ë…„)',
            'HGVC ì „ìš©ì´ ì•„ë‹˜',
        ],
        'warning': 'âœ… ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íƒ€ì„ì‰ì–´ ë§ˆì¼“í”Œë ˆì´ìŠ¤. Verified ë°°ì§€ ë§¤ë¬¼ ê¶Œì¥.',
    },
    'smtsn': {
        'name': 'SellMyTimeshareNow',
        'url': 'sellmytimesharenow.com',
        'rating': 'â­â­â­ 3.5/5',
        'pros': [
            '2003ë…„ë¶€í„° ìš´ì˜',
            'ì¼ì¼ ë°©ë¬¸ì 10,000+',
            'êµ¬ë§¤ìì—ê²Œ ì¢‹ì€ í”Œë«í¼',
        ],
        'cons': [
            'BBB ë¯¸ì¸ì¦',
            'íŒë§¤ì ë¦¬ë·° ë¶€ì •ì  (ê¸´ ëŒ€ê¸° ì‹œê°„)',
            'ì„ ë¶ˆ ìˆ˜ìˆ˜ë£Œ ìš”êµ¬',
        ],
        'warning': 'âš ï¸ êµ¬ë§¤/ê²€ìƒ‰ìš©ìœ¼ë¡œëŠ” OK. íŒë§¤ìë¡œì„œëŠ” ì£¼ì˜ í•„ìš”.',
    },
}


def run_scraping(source: str):
    """ë²”ìš© ìŠ¤í¬ë˜í•‘ ì‹¤í–‰ í•¨ìˆ˜"""
    session = get_session()
    log = create_scrape_log(session, source)

    try:
        # ìŠ¤í¬ë˜í¼ ì„ íƒ
        if source == 'tug':
            scraper = TUGScraper()
        elif source == 'redweek':
            scraper = RedWeekScraper()
        elif source == 'smtsn':
            scraper = SMTSNScraper()
        else:
            raise ValueError(f"Unknown source: {source}")

        listings = scraper.scrape_listings()

        new_count = 0
        updated_count = 0

        for listing_data in listings:
            listing, is_new = upsert_listing(session, listing_data)
            if is_new:
                new_count += 1
            else:
                updated_count += 1

        session.commit()
        complete_scrape_log(
            session, log,
            found=len(listings),
            new=new_count,
            updated=updated_count,
            status='completed'
        )

        return {
            'success': True,
            'found': len(listings),
            'new': new_count,
            'updated': updated_count
        }

    except Exception as e:
        session.rollback()
        complete_scrape_log(
            session, log,
            found=0, new=0, updated=0,
            status='failed',
            error=str(e)
        )
        return {
            'success': False,
            'error': str(e)
        }
    finally:
        session.close()


def run_tug_scraping():
    """TUG Marketplace ìŠ¤í¬ë˜í•‘ ì‹¤í–‰ (í•˜ìœ„í˜¸í™˜)"""
    return run_scraping('tug')


def import_mf_csv(df: pd.DataFrame) -> dict:
    """MF CSV ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    session = get_session()
    try:
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
        clear_mf_references(session)

        count = 0
        for _, row in df.iterrows():
            resort_name = row.get('resort_name', '')
            points = row.get('points', 0)
            annual_mf = row.get('annual_mf', 0)

            if not resort_name or not annual_mf:
                continue

            mf_per_point = annual_mf / points if points > 0 else 0

            mf_data = {
                'resort_name': resort_name,
                'resort_name_normalized': normalize_resort_name(resort_name),
                'unit_type': row.get('unit_type', ''),
                'season': row.get('season', 'Platinum'),
                'points': int(points) if points else 0,
                'annual_mf': float(annual_mf),
                'mf_per_point': mf_per_point,
                'year': int(row.get('year', 2025)),
                'source': 'manual',
            }

            add_mf_reference(session, mf_data)
            count += 1

        session.commit()
        return {'success': True, 'count': count}

    except Exception as e:
        session.rollback()
        return {'success': False, 'error': str(e)}
    finally:
        session.close()


def get_db_stats() -> dict:
    """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ"""
    session = get_session()
    try:
        listing_count = session.query(Listing).count()
        active_count = session.query(Listing).filter(Listing.is_active == True).count()
        mf_count = session.query(MFReference).count()

        return {
            'listing_count': listing_count,
            'active_count': active_count,
            'mf_count': mf_count,
        }
    finally:
        session.close()


def main():
    st.title("ë°ì´í„° ê´€ë¦¬")

    # íƒ­ ìƒì„±
    tab1, tab2, tab3 = st.tabs(["ìŠ¤í¬ë˜í•‘", "MF ë°ì´í„°", "DB ìƒíƒœ"])

    # íƒ­ 1: ìŠ¤í¬ë˜í•‘
    with tab1:
        st.subheader("ë§¤ë¬¼ ìŠ¤í¬ë˜í•‘")

        # ê° ì†ŒìŠ¤ë³„ ì¹´ë“œ ë Œë”ë§
        for source_key in ['tug', 'redweek', 'smtsn']:
            info = SCRAPER_INFO[source_key]

            with st.expander(f"**{info['name']}** - {info['rating']}", expanded=(source_key == 'tug')):
                col_info, col_action = st.columns([3, 1])

                with col_info:
                    st.caption(f"ğŸ”— {info['url']}")

                    # ì¥ë‹¨ì 
                    pros_text = " / ".join([f"âœ… {p}" for p in info['pros']])
                    cons_text = " / ".join([f"âŒ {c}" for c in info['cons']])

                    st.markdown(f"**ì¥ì :** {pros_text}")
                    st.markdown(f"**ë‹¨ì :** {cons_text}")

                    # ì£¼ì˜ì‚¬í•­
                    if info['warning'].startswith('âš ï¸'):
                        st.warning(info['warning'])
                    else:
                        st.success(info['warning'])

                with col_action:
                    if st.button(
                        f"{info['name']} ìŠ¤í¬ë˜í•‘",
                        type="primary" if source_key == 'tug' else "secondary",
                        key=f"scrape_{source_key}",
                        use_container_width=True
                    ):
                        with st.spinner(f"{info['name']} ìŠ¤í¬ë˜í•‘ ì¤‘... (2-5ë¶„ ì†Œìš”)"):
                            result = run_scraping(source_key)

                        if result['success']:
                            st.success(
                                f"ì™„ë£Œ! ë°œê²¬: {result['found']}ê°œ, "
                                f"ì‹ ê·œ: {result['new']}ê°œ, "
                                f"ì—…ë°ì´íŠ¸: {result['updated']}ê°œ"
                            )
                        else:
                            st.error(f"ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

        st.markdown("---")

        # ìµœê·¼ ìŠ¤í¬ë˜í•‘ ë¡œê·¸
        st.subheader("ìµœê·¼ ìŠ¤í¬ë˜í•‘ ê¸°ë¡")
        session = get_session()
        try:
            logs = get_recent_scrape_logs(session, limit=10)
            if logs:
                log_data = []
                for log in logs:
                    log_data.append({
                        'ì†ŒìŠ¤': log.source.upper(),
                        'ì‹œì‘ì‹œê°„': log.started_at.strftime('%Y-%m-%d %H:%M') if log.started_at else '',
                        'ìƒíƒœ': 'ì™„ë£Œ' if log.status == 'completed' else ('ì‹¤íŒ¨' if log.status == 'failed' else 'ì§„í–‰ì¤‘'),
                        'ë°œê²¬': log.listings_found,
                        'ì‹ ê·œ': log.listings_new,
                        'ì—…ë°ì´íŠ¸': log.listings_updated,
                    })
                st.dataframe(pd.DataFrame(log_data), use_container_width=True)
            else:
                st.info("ìŠ¤í¬ë˜í•‘ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        finally:
            session.close()

    # íƒ­ 2: MF ë°ì´í„°
    with tab2:
        st.subheader("MF ì°¸ì¡° ë°ì´í„° ê´€ë¦¬")

        st.markdown("""
        ë¦¬ì¡°íŠ¸ë³„ ìœ ì§€ë¹„(Maintenance Fee) ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.

        **CSV í˜•ì‹:**
        ```
        resort_name,unit_type,season,points,annual_mf,year
        "Elara by Hilton Grand Vacations","2BR Grand","Platinum",13440,1331.68,2025
        ```
        """)

        uploaded_file = st.file_uploader(
            "MF ë°ì´í„° CSV ì—…ë¡œë“œ",
            type=['csv'],
            help="resort_name, unit_type, season, points, annual_mf ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤."
        )

        if uploaded_file:
            try:
                df = pd.read_csv(uploaded_file)
                st.write("ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 10í–‰):")
                st.dataframe(df.head(10))

                required_cols = ['resort_name', 'annual_mf']
                missing = [c for c in required_cols if c not in df.columns]

                if missing:
                    st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(missing)}")
                else:
                    if st.button("MF ë°ì´í„° ê°€ì ¸ì˜¤ê¸°", type="primary"):
                        result = import_mf_csv(df)
                        if result['success']:
                            st.success(f"ì„±ê³µ! {result['count']}ê°œ MF ë°ì´í„° ê°€ì ¸ì˜´")
                        else:
                            st.error(f"ì‹¤íŒ¨: {result.get('error')}")

            except Exception as e:
                st.error(f"CSV íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

        st.markdown("---")

        # í˜„ì¬ MF ë°ì´í„° í‘œì‹œ
        st.subheader("í˜„ì¬ MF ë°ì´í„°")
        session = get_session()
        try:
            refs = get_all_mf_references(session)
            if refs:
                ref_data = []
                for r in refs:
                    ref_data.append({
                        'ë¦¬ì¡°íŠ¸': r.resort_name,
                        'ìœ ë‹›': r.unit_type or '',
                        'ì‹œì¦Œ': r.season or '',
                        'í¬ì¸íŠ¸': f"{r.points:,}" if r.points else '',
                        'ì—°ê°„MF': f"${r.annual_mf:,.2f}",
                        'MF/pt': f"${r.mf_per_point:.4f}" if r.mf_per_point else '',
                    })
                st.dataframe(pd.DataFrame(ref_data), use_container_width=True)
            else:
                st.info("MF ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. CSVë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        finally:
            session.close()

    # íƒ­ 3: DB ìƒíƒœ
    with tab3:
        st.subheader("ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ")

        stats = get_db_stats()

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("ì „ì²´ ë§¤ë¬¼", f"{stats['listing_count']:,}ê°œ")

        with col2:
            st.metric("í™œì„± ë§¤ë¬¼", f"{stats['active_count']:,}ê°œ")

        with col3:
            st.metric("MF ì°¸ì¡° ë°ì´í„°", f"{stats['mf_count']:,}ê°œ")

        st.markdown("---")

        # ì†ŒìŠ¤ë³„ ë§¤ë¬¼ ìˆ˜
        st.subheader("ì†ŒìŠ¤ë³„ ë§¤ë¬¼ ìˆ˜")
        session = get_session()
        try:
            from sqlalchemy import func
            source_counts = session.query(
                Listing.source,
                func.count(Listing.id)
            ).group_by(Listing.source).all()

            if source_counts:
                source_data = [{'ì†ŒìŠ¤': s.upper(), 'ë§¤ë¬¼ ìˆ˜': c} for s, c in source_counts]
                st.dataframe(pd.DataFrame(source_data), use_container_width=True)
            else:
                st.info("ë§¤ë¬¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        finally:
            session.close()


# í˜ì´ì§€ ì‹¤í–‰
if __name__ == "__main__":
    main()
else:
    main()
